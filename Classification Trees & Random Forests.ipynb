{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is code for a basic classification tree."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def gini(labels):\n",
    "  class_counts = {}\n",
    "  for l in labels:\n",
    "      if not l in class_counts:\n",
    "          class_counts[l] = 0\n",
    "      class_counts[l] += 1\n",
    "  N = len(labels)\n",
    "  if N==0: return 1\n",
    "  return 1 - sum([class_counts[c]**2 for c in class_counts])/float(N*N)\n",
    "\n",
    "def split_dataset(data, labels, split_ind, split_value):\n",
    "    \"\"\"\n",
    "    Returns\n",
    "    data1 -- the data above the split\n",
    "    data2 -- the data below the split\n",
    "    labels1 -- corresponding to data1\n",
    "    labels2 -- correspodning to data2\n",
    "    \"\"\"\n",
    "    if not data.size:\n",
    "        return data, data, labels, labels\n",
    "    mask = data[:,split_ind] > split_value\n",
    "    comp = np.logical_not(mask)\n",
    "    return data[mask], data[comp], labels[mask], labels[comp]\n",
    "\n",
    "def split_1d(data, labels, split_value):\n",
    "    \"\"\"\n",
    "    Returns\n",
    "    data1 -- the data above the split\n",
    "    data2 -- the data below the split\n",
    "    labels1 -- corresponding to data1\n",
    "    labels2 -- correspodning to data2\n",
    "    \"\"\"\n",
    "    mask = data > split_value\n",
    "    comp = np.logical_not(mask)\n",
    "    return data[mask], data[comp], labels[mask], labels[comp]\n",
    "\n",
    "\n",
    "def information_gain(data, labels, split_value):\n",
    "    data1, data2, labels1, labels2 = split_1d(data, labels, split_value)\n",
    "    npoints = len(labels)\n",
    "    return gini(labels) - (len(labels1)*gini(labels1) + len(labels2)*gini(labels2)) / float(npoints)\n",
    "\n",
    "def best_1dsplit(data, labels):\n",
    "    best_split = None\n",
    "    best_gain = -np.inf\n",
    "    for el in data:\n",
    "        gain = information_gain(data, labels, el)\n",
    "        if gain > best_gain:\n",
    "            best_gain = gain\n",
    "            best_split = el\n",
    "    return best_gain, best_split\n",
    "\n",
    "def optimal_split(data, labels, mask=None):\n",
    "    \"\"\"\n",
    "    Returns\n",
    "    index -- the feature on which to split\n",
    "    value -- the cutoff value to split on\n",
    "    \"\"\"\n",
    "    best_gain = -np.inf\n",
    "    best_index = None\n",
    "    split_value = None\n",
    "    if mask is None:\n",
    "        mask = np.arange(data.shape[1])\n",
    "    for i in mask:\n",
    "        gain, value = best_1dsplit(data[:,i], labels)\n",
    "        if gain > best_gain:\n",
    "            best_index = i\n",
    "            split_value = value\n",
    "            best_gain = gain\n",
    "    return best_index, split_value\n",
    "\n",
    "def mode(arr):\n",
    "    vals={}\n",
    "    mode = None\n",
    "    max_frq = -1\n",
    "    for val in arr:\n",
    "        if not val in vals:\n",
    "            vals[val]=0\n",
    "        vals[val]+=1\n",
    "    for val in vals:\n",
    "        frq = vals[val]\n",
    "        if frq > max_frq:\n",
    "            max_frq = frq\n",
    "            mode = val\n",
    "\n",
    "    return mode\n",
    "\n",
    "class Node:\n",
    "    def __init__(self, data, labels):\n",
    "        self.rightchild = None\n",
    "        self.leftchild = None\n",
    "        self.data = data\n",
    "        self.labels = labels\n",
    "        self.feature = None\n",
    "        self.cutoff = None\n",
    "        self.label = None\n",
    "\n",
    "    def train(self, depth=1, tol = .2, num_vars=None):\n",
    "        if gini(self.labels) < tol or depth <= 0:\n",
    "            self.label = mode(self.labels)\n",
    "            return\n",
    "\n",
    "        #determine best split\n",
    "        mask = None\n",
    "        if num_vars is not None: mask = np.random.choice(np.arange(self.data.shape[1]), num_vars, replace=False)\n",
    "        best_index, best_value = optimal_split(self.data, self.labels, mask)\n",
    "        self.feature = best_index\n",
    "        self.cutoff = best_value\n",
    "        data1, data2, labels1, labels2 = split_dataset(self.data, self.labels, best_index, best_value)\n",
    "        if len(labels1) == len(self.labels) or len(labels2) == len(self.labels):\n",
    "            self.label = mode(self.labels)\n",
    "            return\n",
    "\n",
    "        self.rightchild = Node(data1, labels1)\n",
    "        self.leftchild = Node(data2, labels2)\n",
    "        self.rightchild.train(depth-1, tol, num_vars=num_vars)\n",
    "        self.leftchild.train(depth-1, tol, num_vars=num_vars)\n",
    "\n",
    "    def dump(self, indent=0):\n",
    "        if self.label is not None:\n",
    "            print \" \" * indent + \"Label: \"+str(self.label)\n",
    "            return\n",
    "        print \" \" * indent  + \"Split on feature \"+str(self.feature)+\" cut \" +str(self.cutoff)\n",
    "        if self.rightchild is not None:\n",
    "            self.rightchild.dump(indent+1)\n",
    "        if self.leftchild is not None:\n",
    "            self.leftchild.dump(indent+1)\n",
    "\n",
    "\n",
    "    def predict_labels(self, data):\n",
    "        npoints = data.shape[0]\n",
    "        res = np.zeros(npoints)\n",
    "        for i in xrange(npoints):\n",
    "            res[i] = self.predict_label(data[i,:])\n",
    "        return res\n",
    "\n",
    "    def predict_label(self, data):\n",
    "        if self.label is not None:\n",
    "            return self.label\n",
    "        if data[self.feature]  > self.cutoff:\n",
    "            return self.rightchild.predict_label(data)\n",
    "        else: return self.leftchild.predict_label(data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we load in the titanic dataset, converting the passenger class and sex categorical variables to dummy variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "titanicData = pd.read_csv(\"titanic4real.csv\")\n",
    "\n",
    "def cleanupTitanic(titanicData, changePclass=False):\n",
    "    \"\"\"Returns: X -- features, y--labels\"\"\"\n",
    "    categorical_features = ['Sex']\n",
    "    num_features = ['Fare', 'Age']\n",
    "    if changePclass:\n",
    "        categorical_features.append('Pclass')\n",
    "    else:\n",
    "        num_features.append('Pclass')\n",
    "\n",
    "    labelName = 'Survived'\n",
    "    for feature in num_features:\n",
    "        titanicData[feature] = titanicData[feature].fillna(titanicData[feature].median())\n",
    "    y = titanicData[labelName].as_matrix()\n",
    "\n",
    "    X = titanicData[num_features].as_matrix()\n",
    "    for feature in categorical_features:\n",
    "        X = np.hstack([X, pd.get_dummies(titanicData[feature]).as_matrix()])\n",
    "    #all who did not survive died\n",
    "    y[y!=1] = 0\n",
    "    return X, y\n",
    "\n",
    "features, labels = cleanupTitanic(titanicData, changePclass=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we create a test and training set, with a 60-40 testing training split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "npoints = len(labels)\n",
    "ntrain = int(.6*npoints)\n",
    "mask = np.arange(npoints)\n",
    "np.random.shuffle(mask)\n",
    "train_mask = mask[:ntrain]\n",
    "test_mask = mask[ntrain:]\n",
    "trainf, trainl = features[train_mask], labels[train_mask]\n",
    "testf, testl = features[test_mask], labels[test_mask]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we train a tree of depth 5 and Gini impurity tolerance 1. This should be sufficient for the Titanic data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split on feature 2 cut 0.0\n",
      " Split on feature 6 cut 0.0\n",
      "  Split on feature 0 cut 17.4\n",
      "   Split on feature 1 cut 0.1667\n",
      "    Split on feature 0 cut 31.3875\n",
      "     Label: 0.0\n",
      "     Split on feature 0 cut 31.275\n",
      "      Label: 1.0\n",
      "      Split on feature 1 cut 18.0\n",
      "       Label: 0.0\n",
      "       Label: 0.0\n",
      "    Label: 1.0\n",
      "   Split on feature 0 cut 7.7375\n",
      "    Split on feature 0 cut 14.5\n",
      "     Split on feature 0 cut 15.55\n",
      "      Split on feature 1 cut 19.0\n",
      "       Label: 1.0\n",
      "       Label: 1.0\n",
      "      Split on feature 0 cut 15.5\n",
      "       Label: 0.0\n",
      "       Label: 1.0\n",
      "     Split on feature 1 cut 19.0\n",
      "      Split on feature 0 cut 7.8792\n",
      "       Label: 0.0\n",
      "       Label: 1.0\n",
      "      Split on feature 0 cut 7.8792\n",
      "       Label: 1.0\n",
      "       Label: 0.0\n",
      "    Split on feature 1 cut 18.5\n",
      "     Label: 1.0\n",
      "     Split on feature 1 cut 18.0\n",
      "      Label: 0.0\n",
      "      Label: 1.0\n",
      "  Split on feature 0 cut 31.6792\n",
      "   Label: 1.0\n",
      "   Split on feature 0 cut 31.0\n",
      "    Label: 0.0\n",
      "    Split on feature 0 cut 12.65\n",
      "     Split on feature 0 cut 13.0\n",
      "      Split on feature 1 cut 25.0\n",
      "       Label: 1.0\n",
      "       Label: 1.0\n",
      "      Split on feature 1 cut 30.0\n",
      "       Label: 1.0\n",
      "       Label: 0.0\n",
      "     Label: 1.0\n",
      " Split on feature 1 cut 8.0\n",
      "  Split on feature 4 cut 0.0\n",
      "   Split on feature 1 cut 52.0\n",
      "    Label: 0.0\n",
      "    Split on feature 0 cut 134.5\n",
      "     Split on feature 0 cut 263.0\n",
      "      Label: 1.0\n",
      "      Label: 0.0\n",
      "     Split on feature 0 cut 110.8833\n",
      "      Label: 1.0\n",
      "      Split on feature 1 cut 38.0\n",
      "       Label: 0.0\n",
      "       Label: 0.0\n",
      "   Split on feature 1 cut 32.0\n",
      "    Label: 0.0\n",
      "    Split on feature 1 cut 31.0\n",
      "     Split on feature 0 cut 22.525\n",
      "      Split on feature 0 cut 56.4958\n",
      "       Label: 0.0\n",
      "       Label: 1.0\n",
      "      Split on feature 0 cut 7.5792\n",
      "       Label: 0.0\n",
      "       Label: 1.0\n",
      "     Split on feature 0 cut 7.8208\n",
      "      Split on feature 0 cut 7.8958\n",
      "       Label: 0.0\n",
      "       Label: 0.0\n",
      "      Split on feature 0 cut 7.775\n",
      "       Label: 1.0\n",
      "       Label: 0.0\n",
      "  Split on feature 6 cut 0.0\n",
      "   Split on feature 0 cut 20.575\n",
      "    Split on feature 0 cut 31.3875\n",
      "     Label: 0.0\n",
      "     Split on feature 0 cut 29.125\n",
      "      Label: 1.0\n",
      "      Label: 0.0\n",
      "    Split on feature 1 cut 0.75\n",
      "     Label: 1.0\n",
      "     Label: 0.0\n",
      "   Label: 1.0\n"
     ]
    }
   ],
   "source": [
    "tree = Node(trainf, trainl)\n",
    "tree.train(depth=7, tol=.1)\n",
    "tree.dump()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the initial split is on feature index 2, which corresponds to gender. Most of the remaining splits are on age and fare. This is unsurprising."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy 0.778626\n"
     ]
    }
   ],
   "source": [
    "predLabels = tree.predict_labels(testf)\n",
    "print \"Accuracy %f\" %( np.sum(testl==predLabels) / float(len(predLabels)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Forest:\n",
    "    def __init__(self, data, labels, tol=.1, max_depth=5, num_trees=100, num_vars=2):\n",
    "        self.num_vars = num_vars\n",
    "        self.data = data\n",
    "        self.labels = labels\n",
    "        self.tol = tol\n",
    "        self.max_depth = max_depth\n",
    "        self.num_trees = num_trees\n",
    "        self.trees = []\n",
    "        for i in xrange(num_trees):\n",
    "            n = Node(data, labels)\n",
    "            n.train(max_depth, tol=tol, num_vars=num_vars)\n",
    "            self.trees.append(n)\n",
    "            print \"Trained Tree %d\" %i\n",
    "    \n",
    "    def predict_label(self, point):\n",
    "        l = [n.predict_label(point) for n in self.trees]\n",
    "        return mode(l)\n",
    "    \n",
    "    def predict_labels(self, data):\n",
    "        return np.array([self.predict_label(point) for point in data])\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trained Tree 0\n",
      "Trained Tree 1\n",
      "Trained Tree 2\n",
      "Trained Tree 3\n",
      "Trained Tree 4\n",
      "Trained Tree 5\n",
      "Trained Tree 6\n",
      "Trained Tree 7\n",
      "Trained Tree 8\n",
      "Trained Tree 9\n",
      "Accuracy: 0.784351\n"
     ]
    }
   ],
   "source": [
    "forest= Forest(trainf, trainl, max_depth=7, num_trees=10, num_vars=2)\n",
    "fpl = forest.predict_labels(testf)\n",
    "print \"Accuracy: %f\" % (np.sum(fpl==testl)/float(len(testl)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The forest is better than a single tree."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
